# Consumer properties
spring.kafka.consumer.bootstrap-servers=http://localhost:9092

# Auto Offset Reset
# What to do when there is no initial offset in Kafka or if 
# the current offset does not exist any more on the server (e.g. because that data has been deleted): 
#https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_auto.offset.reset
spring.kafka.consumer.auto-offset-reset=earliest

# Enagle Auto Commit
# Defines if offsets will be committed automatically in background
# The recommendation is always use manual acknowledge to avoid data loss
# With manual offset commit you have more control when to commit offsets to kafka
# https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_enable.auto.commit
spring.kafka.consumer.enable-auto-commit=false

spring.kafka.consumer.group-id=kafka-consumer-id
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
spring.kafka.consumer.properties.schema.registry.url=http://localhost:8081

specific.avro.reader=true

# For high throughput consumer consider tuning this property
# Receive Buffer Bytes
# The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.
# Default value is 65536 bytes (64 kilobytes)
# https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_receive.buffer.bytes
# For high-bandwidth networks (10 Gbps or higher) with latencies of 1 millisecond or more, 
# consider setting the socket buffers to 8 or 16 MB. If memory is scarce, consider 1 MB. 
# You can also use a value of -1, which lets the underlying operating system tune the buffer 
# size based on network conditions. However, the automatic tuning might not occur fast 
# enough for consumers that need to start "hot." Ref.: https://newrelic.com/blog/best-practices/kafka-best-practices#consumers
#spring.kafka.consumer.receive-buffer-bytes

topic.name=push.vehicle-position-coordinate.created

###############################################################
## Producer Properties for the Dead Letter Topic Retry Policy
spring.kafka.producer.group-id=my-producer
spring.kafka.producer.bootstrap-servers=http://localhost:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
spring.kafka.producer.properties.schema.registry.url=http://localhost:8081

# The producer groups together any records that arrive in between request transmissions into a single batched request
# https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#producerconfigs_linger.ms
# Linger MS
# Time to wait for batching requests instead of always send requests right away after asked
# Time in milliseconds to wait.
#spring.kafka.producer.linger_ms=10

# This means the producer will wait for the full set of minimal in-sync replicas to acknowledge the record
spring.kafka.producer.acks=all

# This means trying the max attempts value to transition error. For example as eventually unavailability of kafka broker.
spring.kafka.producer.retries=10000000

# This means kafka will guaratee not duplicated messages in case some connection error with kafka broker for example.
# Here's a post explaning this property in detail: https://www.cloudkarafka.com/blog/apache-kafka-idempotent-producer-avoiding-message-duplication.html
spring.kafka.producer.idempotence_enabled=true
###############################################################
